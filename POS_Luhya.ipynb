{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gN37K6YkvfHr",
        "7hfWs_c10MTm",
        "aZa1MBK3Byd9",
        "1sZZsHZY_oep",
        "qoK1gqxEm80T"
      ],
      "authorship_tag": "ABX9TyO0VOK1VUIBE/mUMZA3iXuG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EdnahM/NLP_POS_Luhya/blob/main/POS_Luhya.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "### Natural Language Processing\n",
        "### Edna Wairimu Mugoh\n",
        "### C241-01-2293/2022"
      ],
      "metadata": {
        "id": "0PBwqNrRlCqy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below project is a POS task on Luhya Dataset-Specialized with the Busukusu Speaking\n",
        "\n",
        "Project Parts\n",
        "1. Data preprocessing\n",
        "2. Training and Modelling\n",
        "3. Model Evaluation\n",
        "4. Developing a usable endpoint\n",
        "5. Deployed POS app for Bukusu"
      ],
      "metadata": {
        "id": "xoffocJqlHIX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preporcessing\n"
      ],
      "metadata": {
        "id": "Km5D8ybBlHZo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import required libraries\n"
      ],
      "metadata": {
        "id": "000Xu5XllxCE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "M1-dqBC7A1Ft"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Dataset\n"
      ],
      "metadata": {
        "id": "TdscfQUCtgBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BjHF3qMuAWt",
        "outputId": "3b52b8a1-26b2-4a0f-e13b-cdd043783b2a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfaMuUotuAJL",
        "outputId": "88d88e7a-4ebf-48aa-aeee-fe56e7ebf4e8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df =  pd.read_csv(\"/content/drive/MyDrive/MSC-DS-2023/combined_bukusu_train_data.csv\", header=0)\n",
        "test_df =  pd.read_csv(\"/content/drive/MyDrive/MSC-DS-2023/combined_bukusu_test_data.csv\", header=0)"
      ],
      "metadata": {
        "id": "6JFRu50xtjur"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zi1doD_lva63",
        "outputId": "d9a4c9e8-94f1-4e8c-99d2-d667b2df403c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         WORD SPEECH TAG\n",
              "0     BAABIYA         NN\n",
              "1       BAALA         NN\n",
              "2  BAABANGURA        ADJ\n",
              "3       BAALA         NN\n",
              "4    BALUBIRI        ADJ"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72c164f5-7bc1-47e9-a55f-d8847b8f6eef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WORD</th>\n",
              "      <th>SPEECH TAG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BAABIYA</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BAALA</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BAABANGURA</td>\n",
              "      <td>ADJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BAALA</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BALUBIRI</td>\n",
              "      <td>ADJ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72c164f5-7bc1-47e9-a55f-d8847b8f6eef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-72c164f5-7bc1-47e9-a55f-d8847b8f6eef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-72c164f5-7bc1-47e9-a55f-d8847b8f6eef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0051f090-dbf1-458c-aceb-c74939cfc233\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0051f090-dbf1-458c-aceb-c74939cfc233')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0051f090-dbf1-458c-aceb-c74939cfc233 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 54542,\n  \"fields\": [\n    {\n      \"column\": \"WORD\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10066,\n        \"samples\": [\n          \"wamanya\",\n          \"Wa\",\n          \"Lusi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SPEECH TAG\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 115,\n        \"samples\": [\n          \"NO\",\n          \"DET\",\n          \"ADp\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcEKrxUx-_-w",
        "outputId": "72fc6fc5-c8c5-45c0-ab1a-2ad77bae10de"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WORD          object\n",
              "SPEECH TAG    object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLwC0kx4_JmM",
        "outputId": "9e55acbd-0cb1-408a-f117-5951893a5178"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54542, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clean Dataset"
      ],
      "metadata": {
        "id": "gN37K6YkvfHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_counts = train_df['SPEECH TAG'].value_counts()\n",
        "print(pos_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yADhOHiXva2L",
        "outputId": "a18ff1d8-019c-4792-e842-beb64d3b6d19"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SPEECH TAG\n",
            "NN            10439\n",
            "V              7561\n",
            "ADP            5593\n",
            "nn             3253\n",
            "CONJ           3113\n",
            "v              2498\n",
            "PRON           2416\n",
            "DET            2398\n",
            "PUNCT          2096\n",
            "conj           1894\n",
            "ADJ            1657\n",
            "ADV            1072\n",
            "punct          1071\n",
            "PUNC            998\n",
            "adp             824\n",
            "pron            767\n",
            "NUM             642\n",
            "adv             445\n",
            "adj             420\n",
            "PREP            262\n",
            "det             186\n",
            "num             143\n",
            "X                80\n",
            "POS              23\n",
            "PRO              18\n",
            "N                16\n",
            "ADJE             14\n",
            "inter            12\n",
            "x                11\n",
            "AP               10\n",
            "n                10\n",
            "pro               9\n",
            "con               8\n",
            "Pron              7\n",
            "D                 7\n",
            "pr                6\n",
            "AV                4\n",
            "AD                4\n",
            "PART              4\n",
            "DP                4\n",
            "cv                4\n",
            "XX                3\n",
            "dp                3\n",
            "VV                3\n",
            "ART               3\n",
            "A                 3\n",
            "AD[               2\n",
            "SPEECH TAG        2\n",
            "C                 2\n",
            "C0NJ              2\n",
            "INTER             2\n",
            "CONJU             2\n",
            "PR                2\n",
            "NU                2\n",
            "nn4               2\n",
            "PUNT              2\n",
            "prom              2\n",
            "ne                2\n",
            "vv                2\n",
            "nnn               2\n",
            "ADDP              2\n",
            "ñn                2\n",
            "NNN               2\n",
            "ADO               2\n",
            "mm                2\n",
            "PU                1\n",
            "NE                1\n",
            "OMUKHAANA         1\n",
            "AADV              1\n",
            "DADV              1\n",
            "YETURI            1\n",
            "YEMA              1\n",
            "TEMA              1\n",
            "AJ                1\n",
            "PRE               1\n",
            "ADDJ              1\n",
            "MASA              1\n",
            "OU                1\n",
            "AADJ              1\n",
            "COJ               1\n",
            "APD               1\n",
            "DJ                1\n",
            "HH                1\n",
            "NM                1\n",
            "pos               1\n",
            "PROUN             1\n",
            "HATATI            1\n",
            "po                1\n",
            "ABAAELESIA        1\n",
            "adadp             1\n",
            "Conj              1\n",
            "asp               1\n",
            "av                1\n",
            "um                1\n",
            "nu                1\n",
            "bakaambisi        1\n",
            "chambukha         1\n",
            "p                 1\n",
            "mala              1\n",
            "ADp               1\n",
            "PR0N              1\n",
            "pun               1\n",
            "asinyikhwa        1\n",
            "NOUN              1\n",
            "adk               1\n",
            "CHIRUPIA          1\n",
            "KHUKHWAMA         1\n",
            "NGA               1\n",
            "BULI              1\n",
            "MBOOLELE          1\n",
            "NO                1\n",
            "ON                1\n",
            "O                 1\n",
            "DV                1\n",
            "b                 1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Function to standardize the various variations of pos\n"
      ],
      "metadata": {
        "id": "7hfWs_c10MTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize_pos(pos):\n",
        "    \"\"\"\n",
        "    Standardize POS tags to basic presentation\n",
        "    \"\"\"\n",
        "    pos_mapping = {\n",
        "        'N': ['N', 'NN', 'NNN', 'NNNN', 'NOUN','noun', 'nn','NNC', 'NNS','nn4','NO','NU','ñn'], # Noun\n",
        "        'V': ['V', 'VB', 'verb', 'vb','v','VV', 'vv'], # Verb\n",
        "        'PRON':['PR','NNP','PROM','PRO','PRON', 'P','pro', 'PROUN','PR0N'], # Pronoun\n",
        "        'PUNCT':['punct','punc','PUNT'], # Punctuation\n",
        "        'ADJ': ['AD', 'ADJ','adj', 'AD [','ADO',' adje','AADJ','DJ','ADJE','ADDJ','AJ','AD['], # Adjective\n",
        "        'ADV': ['ADV','AV','adv','DV','AV', 'AADV','DADV'], # Adverb\n",
        "        'PREP':['PREP', 'prep','pre'], # Preposition\n",
        "        'CONJ': ['conju', 'conj','CON','C','c', 'COJ', 'C0NJ'], # Conjuction\n",
        "        'INT': ['NUM', 'num',], # Integer\n",
        "        'DT': ['DET','DT','D'], # Determiner\n",
        "        'INTJ': ['inter',''], # Interjection\n",
        "        'XX' : ['XX', 'X'], # Unknown\n",
        "        'ADP' :['AP', 'ADP','adp','ADDP','addp','APD', 'adadp','dp'], # Adposition\n",
        "\n",
        "    }\n",
        "\n",
        "   # Checking Null POC\n",
        "    if pd.isna(pos):\n",
        "      pos = 'PUNCT'\n",
        "      return pos\n",
        "\n",
        "    pos_upper = pos.upper().strip()\n",
        "\n",
        "    for standard_pos, variations in pos_mapping.items():\n",
        "        for variation in variations:\n",
        "            if pos_upper == variation.upper():\n",
        "                return standard_pos\n",
        "\n",
        "    return pos\n"
      ],
      "metadata": {
        "id": "22lJzNo_zAPm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize_pos_column(df, column_name):\n",
        "    df[column_name] = df[column_name].apply(standardize_pos)\n",
        "    return df"
      ],
      "metadata": {
        "id": "nA-MWljn0L_b"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df = standardize_pos_column(train_df, 'SPEECH TAG')"
      ],
      "metadata": {
        "id": "Kt7NRYhOzACK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the filtered DataFrame\n",
        "pos_counts = cleaned_df['SPEECH TAG'].value_counts()\n",
        "print(\"Cleaned  POS Dataframe\")\n",
        "print(pos_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDw6IG5Ay_9P",
        "outputId": "be227e9f-7b0e-4cd5-8892-1f061380f58c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned  POS Dataframe\n",
            "SPEECH TAG\n",
            "N             13731\n",
            "V             10064\n",
            "PUNCT          8607\n",
            "ADP            6439\n",
            "CONJ           5023\n",
            "PRON           3230\n",
            "DT             2591\n",
            "ADJ            2103\n",
            "ADV            1525\n",
            "INT             785\n",
            "PREP            263\n",
            "XX               94\n",
            "POS              23\n",
            "INTJ             14\n",
            "PART              4\n",
            "cv                4\n",
            "ART               3\n",
            "A                 3\n",
            "ne                2\n",
            "mm                2\n",
            "SPEECH TAG        2\n",
            "ON                1\n",
            "TEMA              1\n",
            "ABAAELESIA        1\n",
            "MASA              1\n",
            "HATATI            1\n",
            "YEMA              1\n",
            "PU                1\n",
            "NM                1\n",
            "YETURI            1\n",
            "OMUKHAANA         1\n",
            "HH                1\n",
            "NE                1\n",
            "OU                1\n",
            "O                 1\n",
            "po                1\n",
            "MBOOLELE          1\n",
            "BULI              1\n",
            "NGA               1\n",
            "KHUKHWAMA         1\n",
            "CHIRUPIA          1\n",
            "asp               1\n",
            "b                 1\n",
            "asinyikhwa        1\n",
            "um                1\n",
            "bakaambisi        1\n",
            "chambukha         1\n",
            "mala              1\n",
            "pun               1\n",
            "adk               1\n",
            "pos               1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mQzRmJnQy_uW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Eliminate all rows with pos_count count of 1"
      ],
      "metadata": {
        "id": "zo2TcWZgxubK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_v1 = train_df.copy()\n",
        "pos_to_keep = pos_counts[pos_counts != 1].index\n",
        "\n",
        "cleaned_df = train_df[train_df['SPEECH TAG'].isin(pos_to_keep)]\n",
        "\n",
        "# Display the filtered DataFrame\n",
        "pos_counts = cleaned_df['SPEECH TAG'].value_counts()\n",
        "print(\"Cleaned  POS Dataframe\")\n",
        "print(pos_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDMxrt7AvazU",
        "outputId": "1b097487-4b59-4971-d71b-7f7d45bd1e14"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned  POS Dataframe\n",
            "SPEECH TAG\n",
            "N             13731\n",
            "V             10064\n",
            "PUNCT          8607\n",
            "ADP            6439\n",
            "CONJ           5023\n",
            "PRON           3230\n",
            "DT             2591\n",
            "ADJ            2103\n",
            "ADV            1525\n",
            "INT             785\n",
            "PREP            263\n",
            "XX               94\n",
            "POS              23\n",
            "INTJ             14\n",
            "cv                4\n",
            "PART              4\n",
            "ART               3\n",
            "A                 3\n",
            "SPEECH TAG        2\n",
            "ne                2\n",
            "mm                2\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bqkRGdHHxt_i"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F8FFwY2avapp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization and Lemmatization on the given Words"
      ],
      "metadata": {
        "id": "aZa1MBK3Byd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import spacy"
      ],
      "metadata": {
        "id": "gdcaFrBSCIAw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5U-Q6TWCn4g",
        "outputId": "ea238364-441e-4f63-a082-53a72e8475d3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df['WORD'] = cleaned_df['WORD'].astype(str)\n",
        "cleaned_df['TOKENS'] = cleaned_df['WORD'].apply(word_tokenize)\n"
      ],
      "metadata": {
        "id": "BXuuhoSZCNtg"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm') ## Lemmatization"
      ],
      "metadata": {
        "id": "_EO0kpNgCtuF"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_text(text):\n",
        "    doc = nlp(\" \".join(text))\n",
        "    return [token.lemma_ for token in doc]"
      ],
      "metadata": {
        "id": "apLtEDMmCDar"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df['LEMMAS'] = cleaned_df['TOKENS'].apply(lemmatize_text)"
      ],
      "metadata": {
        "id": "ikDPrZR4CDRz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cleaned_df.tail(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16H-JeiSCDFa",
        "outputId": "f8dd7d14-5f90-4587-d71a-8d893e0f1c6b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                WORD SPEECH TAG           TOKENS           LEMMAS\n",
            "54532           niio        ADV           [niio]           [niio]\n",
            "54533       kumubili          N       [kumubili]       [kumubili]\n",
            "54534  kwanyooleekha          V  [kwanyooleekha]  [kwanyooleekha]\n",
            "54535             Se      PUNCT             [Se]             [Se]\n",
            "54536      okhoyeele          V      [okhoyeele]      [okhoyeele]\n",
            "54537       omukusie          V       [omukusie]       [omukusie]\n",
            "54538          namwe        ADV          [namwe]          [namwe]\n",
            "54539       omukhole          V       [omukhole]       [omukhole]\n",
            "54540     balarobora          V     [balarobora]     [balarobora]\n",
            "54541        emasoti          N        [emasoti]        [emasoti]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "BZyvdtXJmTJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using the NLTK Library for training"
      ],
      "metadata": {
        "id": "1sZZsHZY_oep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Install and Import the required Libraries"
      ],
      "metadata": {
        "id": "KzkP44puA5y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install nltk spacy textblob stanfordnlp pattern gensim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMLMLCNZAzj3",
        "outputId": "6b12e38b-9473-4c27-c399-fac1f6824d25"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Collecting stanfordnlp\n",
            "  Downloading stanfordnlp-0.2.0-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pattern\n",
            "  Downloading Pattern-3.6.0.tar.gz (22.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from stanfordnlp) (3.20.3)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from stanfordnlp) (2.2.1+cu121)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pattern) (0.18.3)\n",
            "Collecting backports.csv (from pattern)\n",
            "  Downloading backports.csv-1.0.7-py2.py3-none-any.whl (12 kB)\n",
            "Collecting mysqlclient (from pattern)\n",
            "  Downloading mysqlclient-2.2.4.tar.gz (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from pattern) (4.12.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from pattern) (4.9.4)\n",
            "Collecting feedparser (from pattern)\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six (from pattern)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pattern) (1.11.4)\n",
            "Collecting python-docx (from pattern)\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cherrypy (from pattern)\n",
            "  Downloading CherryPy-18.9.0-py3-none-any.whl (348 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.8/348.8 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->stanfordnlp) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->stanfordnlp) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->stanfordnlp) (3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->stanfordnlp) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.0.0->stanfordnlp)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.0.0->stanfordnlp)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.0.0->stanfordnlp)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.0.0->stanfordnlp)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/nvidia-cublas-cu12/\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.0.0->stanfordnlp)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.0.0->stanfordnlp)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.0.0->stanfordnlp)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.0.0->stanfordnlp)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.0.0->stanfordnlp)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.0.0->stanfordnlp)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.0.0->stanfordnlp)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->stanfordnlp) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->stanfordnlp)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->pattern) (2.5)\n",
            "Collecting cheroot>=8.2.1 (from cherrypy->pattern)\n",
            "  Downloading cheroot-10.0.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.8/104.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portend>=2.1.1 (from cherrypy->pattern)\n",
            "  Downloading portend-3.2.0-py3-none-any.whl (5.3 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from cherrypy->pattern) (10.1.0)\n",
            "Collecting zc.lockfile (from cherrypy->pattern)\n",
            "  Downloading zc.lockfile-3.0.post1-py3-none-any.whl (9.8 kB)\n",
            "Collecting jaraco.collections (from cherrypy->pattern)\n",
            "  Downloading jaraco.collections-5.0.1-py3-none-any.whl (10 kB)\n",
            "Collecting sgmllib3k (from feedparser->pattern)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->pattern) (42.0.7)\n",
            "Collecting jaraco.functools (from cheroot>=8.2.1->cherrypy->pattern)\n",
            "  Downloading jaraco.functools-4.0.1-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->pattern) (1.16.0)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n",
            "Collecting tempora>=1.8 (from portend>=2.1.1->cherrypy->pattern)\n",
            "  Downloading tempora-5.5.1-py3-none-any.whl (13 kB)\n",
            "Collecting jaraco.text (from jaraco.collections->cherrypy->pattern)\n",
            "  Downloading jaraco.text-3.12.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->stanfordnlp) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->pattern) (2.22)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern) (2023.4)\n",
            "Collecting jaraco.context>=4.1 (from jaraco.text->jaraco.collections->cherrypy->pattern)\n",
            "  Downloading jaraco.context-5.3.0-py3-none-any.whl (6.5 kB)\n",
            "Collecting autocommand (from jaraco.text->jaraco.collections->cherrypy->pattern)\n",
            "  Downloading autocommand-2.2.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (7.0.0)\n",
            "Collecting backports.tarfile (from jaraco.context>=4.1->jaraco.text->jaraco.collections->cherrypy->pattern)\n",
            "  Downloading backports.tarfile-1.1.1-py3-none-any.whl (29 kB)\n",
            "Building wheels for collected packages: pattern, mysqlclient, sgmllib3k\n",
            "  Building wheel for pattern (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pattern: filename=Pattern-3.6-py3-none-any.whl size=22332702 sha256=0eff152195edd013680e8bc29e14a56d2e315f8fb2500bbddfdf420f8a4dcc3c\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/8f/40/fe23abd593ef60be5bfaf3e02154d3484df42aa947bbf4d499\n",
            "  Building wheel for mysqlclient (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mysqlclient: filename=mysqlclient-2.2.4-cp310-cp310-linux_x86_64.whl size=124729 sha256=4325b01d50636bbf6b4004599ba22521e0ca7f273a0114db6c8af00f9d107654\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/96/ac/2a4d8cb58a4d95de1dffc3f8b0ea42e0e5b63ab97640edbda3\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6049 sha256=1c0dcdf7b87673eb14e1ff310aa2c64199e5d3893ed480690a5506e6554f6bd1\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
            "Successfully built pattern mysqlclient sgmllib3k\n",
            "Installing collected packages: sgmllib3k, backports.csv, zc.lockfile, python-docx, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mysqlclient, jaraco.functools, feedparser, backports.tarfile, autocommand, tempora, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jaraco.context, cheroot, portend, pdfminer.six, nvidia-cusolver-cu12, jaraco.text, stanfordnlp, jaraco.collections, cherrypy, pattern\n",
            "Successfully installed autocommand-2.2.2 backports.csv-1.0.7 backports.tarfile-1.1.1 cheroot-10.0.1 cherrypy-18.9.0 feedparser-6.0.11 jaraco.collections-5.0.1 jaraco.context-5.3.0 jaraco.functools-4.0.1 jaraco.text-3.12.0 mysqlclient-2.2.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pattern-3.6 pdfminer.six-20231228 portend-3.2.0 python-docx-1.1.2 sgmllib3k-1.0.0 stanfordnlp-0.2.0 tempora-5.5.1 zc.lockfile-3.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import spacy\n",
        "from textblob import TextBlob\n",
        "import stanfordnlp\n",
        "import pattern\n",
        "import gensim\n",
        "from nltk.corpus import treebank"
      ],
      "metadata": {
        "id": "LcHdHccFm7hb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lOQPGjRwO5iY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xMux25ViO5UY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Function to define POS:"
      ],
      "metadata": {
        "id": "ZIyQBtH6O4_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def features(word):\n",
        "    return {'word': word}"
      ],
      "metadata": {
        "id": "bVdMWq7ZQkNf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features from your dataset\n",
        "data = []\n",
        "for index, row in cleaned_df.iterrows():\n",
        "    word = row['WORD']\n",
        "    tag = row['SPEECH TAG']\n",
        "    featureset = features(word)\n",
        "    data.append((featureset, tag))"
      ],
      "metadata": {
        "id": "yeszPQG7Qpyu"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "train_size = int(0.8 * len(data))\n",
        "train_set, test_set = data[:train_size], data[train_size:]"
      ],
      "metadata": {
        "id": "hMzXs_RKQzpa"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = nltk.MaxentClassifier.train(train_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oOdtUecQzdR",
        "outputId": "97aa8a61-d8b4-4af9-c1d2-8fc9632d606a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ==> Training (100 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -3.04452        0.000\n",
            "             2          -0.82474        0.867\n",
            "             3          -0.57755        0.867\n",
            "             4          -0.47056        0.867\n",
            "             5          -0.41047        0.867\n",
            "             6          -0.37192        0.867\n",
            "             7          -0.34506        0.867\n",
            "             8          -0.32526        0.867\n",
            "             9          -0.31007        0.867\n",
            "            10          -0.29804        0.867\n",
            "            11          -0.28827        0.867\n",
            "            12          -0.28019        0.867\n",
            "            13          -0.27338        0.867\n",
            "            14          -0.26758        0.867\n",
            "            15          -0.26257        0.867\n",
            "            16          -0.25820        0.867\n",
            "            17          -0.25436        0.867\n",
            "            18          -0.25095        0.867\n",
            "            19          -0.24791        0.867\n",
            "            20          -0.24517        0.867\n",
            "            21          -0.24271        0.867\n",
            "            22          -0.24047        0.867\n",
            "            23          -0.23843        0.867\n",
            "            24          -0.23656        0.867\n",
            "            25          -0.23484        0.867\n",
            "            26          -0.23326        0.867\n",
            "            27          -0.23179        0.867\n",
            "            28          -0.23044        0.867\n",
            "            29          -0.22917        0.867\n",
            "            30          -0.22800        0.867\n",
            "            31          -0.22689        0.867\n",
            "            32          -0.22586        0.867\n",
            "            33          -0.22490        0.867\n",
            "            34          -0.22398        0.867\n",
            "            35          -0.22313        0.867\n",
            "            36          -0.22232        0.867\n",
            "            37          -0.22155        0.867\n",
            "            38          -0.22083        0.867\n",
            "            39          -0.22014        0.867\n",
            "            40          -0.21949        0.867\n",
            "            41          -0.21887        0.867\n",
            "            42          -0.21827        0.867\n",
            "            43          -0.21771        0.867\n",
            "            44          -0.21717        0.867\n",
            "            45          -0.21666        0.867\n",
            "            46          -0.21617        0.867\n",
            "            47          -0.21570        0.867\n",
            "            48          -0.21525        0.867\n",
            "            49          -0.21482        0.867\n",
            "            50          -0.21440        0.867\n",
            "            51          -0.21401        0.867\n",
            "            52          -0.21362        0.867\n",
            "            53          -0.21326        0.867\n",
            "            54          -0.21290        0.867\n",
            "            55          -0.21256        0.867\n",
            "            56          -0.21223        0.867\n",
            "            57          -0.21192        0.867\n",
            "            58          -0.21161        0.867\n",
            "            59          -0.21131        0.867\n",
            "            60          -0.21103        0.867\n",
            "            61          -0.21075        0.867\n",
            "            62          -0.21048        0.867\n",
            "            63          -0.21022        0.867\n",
            "            64          -0.20997        0.867\n",
            "            65          -0.20973        0.867\n",
            "            66          -0.20949        0.867\n",
            "            67          -0.20927        0.867\n",
            "            68          -0.20904        0.867\n",
            "            69          -0.20883        0.867\n",
            "            70          -0.20862        0.867\n",
            "            71          -0.20842        0.867\n",
            "            72          -0.20822        0.867\n",
            "            73          -0.20803        0.867\n",
            "            74          -0.20784        0.867\n",
            "            75          -0.20766        0.867\n",
            "            76          -0.20748        0.867\n",
            "            77          -0.20731        0.867\n",
            "            78          -0.20714        0.867\n",
            "            79          -0.20698        0.867\n",
            "            80          -0.20682        0.867\n",
            "            81          -0.20666        0.867\n",
            "            82          -0.20651        0.867\n",
            "            83          -0.20636        0.867\n",
            "            84          -0.20622        0.867\n",
            "            85          -0.20608        0.867\n",
            "            86          -0.20594        0.867\n",
            "            87          -0.20580        0.867\n",
            "            88          -0.20567        0.867\n",
            "            89          -0.20554        0.867\n",
            "            90          -0.20542        0.867\n",
            "            91          -0.20529        0.867\n",
            "            92          -0.20517        0.867\n",
            "            93          -0.20506        0.867\n",
            "            94          -0.20494        0.867\n",
            "            95          -0.20483        0.867\n",
            "            96          -0.20472        0.867\n",
            "            97          -0.20461        0.867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = nltk.classify.accuracy(classifier, test_set)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "P82lQeE-QzQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save the predictions to a pickle file."
      ],
      "metadata": {
        "id": "yMwMasK8p1A_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('pos_tagger.pickle', 'wb') as f:\n",
        "    pickle.dump(classifier, f)"
      ],
      "metadata": {
        "id": "j2vxxKSnm8LV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using the Spacy Library for training"
      ],
      "metadata": {
        "id": "OZqPyIne_vWF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "qoK1gqxEm80T"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aIzLNeLxnWVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3NS49RAgnW3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ey-Ftfp1nWrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "V0Wl5M5hnXak"
      }
    }
  ]
}