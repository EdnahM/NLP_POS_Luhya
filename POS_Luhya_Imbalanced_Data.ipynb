{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EdnahM/NLP_POS_Luhya/blob/dev/POS_Luhya_Imbalanced_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIWH_Q2jqZtF"
      },
      "source": [
        "#### Deep Learning Nueral Network solving imbalanced data by class weighting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LH236tZxqZcq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, TimeDistributed, Dense\n",
        "from tensorflow.keras.initializers import Orthogonal, RandomUniform, GlorotUniform, Zeros\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-pvJlFmsAH4",
        "outputId": "bbc148eb-85c4-4fa7-b347-79a29ce44f1b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import os\n",
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAJ83kQhsCCS",
        "outputId": "d31974d9-dab1-4455-89e8-ec59e4f04e79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4G_l7fr4sp29"
      },
      "outputs": [],
      "source": [
        "data =  pd.read_csv(\"/content/drive/MyDrive/MSC-DS-2023/cleaned_data.csv\", header=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oq73CzY5rxGZ"
      },
      "outputs": [],
      "source": [
        "words = list(set(data[\"WORD\"].values))\n",
        "n_words = len(words)\n",
        "tags = list(set(data[\"SPEECH TAG\"].values))\n",
        "n_tags = len(tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6R_93E0VxdQs"
      },
      "outputs": [],
      "source": [
        "\n",
        "word2idx = {w: i + 2 for i, w in enumerate(words)}\n",
        "word2idx[\"UNK\"] = 1\n",
        "word2idx[\"PAD\"] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-u1AKjybxiDj"
      },
      "outputs": [],
      "source": [
        "tag2idx = {t: i for i, t in enumerate(tags)}\n",
        "idx2tag = {i: t for t, i in tag2idx.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__eAKLFjxmnT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "# data = pd.read_csv('cleaned_data.csv')\n",
        "data =  pd.read_csv(\"/content/drive/MyDrive/MSC-DS-2023/cleaned_data.csv\", header=0)\n",
        "\n",
        "# Prepare word and tag mappings\n",
        "words = list(set(data[\"WORD\"].values))\n",
        "n_words = len(words)\n",
        "tags = list(set(data[\"SPEECH TAG\"].values))\n",
        "n_tags = len(tags)\n",
        "\n",
        "word2idx = {w: i + 2 for i, w in enumerate(words)}\n",
        "word2idx[\"UNK\"] = 1\n",
        "word2idx[\"PAD\"] = 0\n",
        "\n",
        "tag2idx = {t: i for i, t in enumerate(tags)}\n",
        "idx2tag = {i: t for t, i in tag2idx.items()}\n",
        "\n",
        "# Group words and tags into sentences\n",
        "sentences = []\n",
        "sentence_tags = []\n",
        "\n",
        "temp_sentence = []\n",
        "temp_tags = []\n",
        "\n",
        "for index, row in data.iterrows():\n",
        "    word = row['WORD']\n",
        "    tag = row['SPEECH TAG']\n",
        "    if word == \".\":\n",
        "        if temp_sentence:  # if the sentence is not empty\n",
        "            sentences.append(temp_sentence)\n",
        "            sentence_tags.append(temp_tags)\n",
        "            temp_sentence = []\n",
        "            temp_tags = []\n",
        "    else:\n",
        "        temp_sentence.append(word)\n",
        "        temp_tags.append(tag)\n",
        "\n",
        "# Add the last sentence if it's not empty\n",
        "if temp_sentence:\n",
        "    sentences.append(temp_sentence)\n",
        "    sentence_tags.append(temp_tags)\n",
        "\n",
        "# Convert words and tags to indices\n",
        "X = [[word2idx.get(w, word2idx[\"UNK\"]) for w in s] for s in sentences]\n",
        "y = [[tag2idx[t] for t in s] for s in sentence_tags]\n",
        "\n",
        "# Pad sequences\n",
        "maxlen = 50  # Choose a suitable maximum length for your sequences\n",
        "X = pad_sequences(X, maxlen=maxlen, padding='post')\n",
        "y = pad_sequences(y, maxlen=maxlen, padding='post')\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Calculate class weights\n",
        "y_flat = [item for sublist in y_train for item in sublist]  # Flatten the list of lists\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_flat), y=y_flat)\n",
        "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Convert y_train and y_test to categorical\n",
        "y_train = np.array([to_categorical(i, num_classes=n_tags) for i in y_train])\n",
        "y_test = np.array([to_categorical(i, num_classes=n_tags) for i in y_test])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, TimeDistributed, Dense\n",
        "\n",
        "# Define model architecture\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=n_words + 2, output_dim=50, input_length=maxlen, mask_zero=True))\n",
        "model.add(Bidirectional(LSTM(units=100, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(n_tags, activation=\"softmax\")))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.1, class_weight=class_weights_dict)\n",
        "\n",
        "# Save the model\n",
        "model.save('pos_model.h5')"
      ],
      "metadata": {
        "id": "lecE8lWOpTOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmriNrdOGb2c",
        "outputId": "5e077f5a-f9f9-4c23-96d1-b160992a81db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "422/422 [==============================] - 60s 117ms/step - loss: 4.5700 - accuracy: 0.3272 - val_loss: 1.2212 - val_accuracy: 0.6656\n",
            "Epoch 2/100\n",
            "422/422 [==============================] - 46s 110ms/step - loss: 0.8286 - accuracy: 0.7705 - val_loss: 0.4801 - val_accuracy: 0.8277\n",
            "Epoch 3/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 0.2700 - accuracy: 0.8970 - val_loss: 0.2591 - val_accuracy: 0.9297\n",
            "Epoch 4/100\n",
            "422/422 [==============================] - 46s 110ms/step - loss: 0.1288 - accuracy: 0.9542 - val_loss: 0.1527 - val_accuracy: 0.9626\n",
            "Epoch 5/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 0.0665 - accuracy: 0.9729 - val_loss: 0.1083 - val_accuracy: 0.9752\n",
            "Epoch 6/100\n",
            "422/422 [==============================] - 48s 113ms/step - loss: 0.0464 - accuracy: 0.9799 - val_loss: 0.0910 - val_accuracy: 0.9786\n",
            "Epoch 7/100\n",
            "422/422 [==============================] - 48s 113ms/step - loss: 0.0262 - accuracy: 0.9862 - val_loss: 0.0676 - val_accuracy: 0.9857\n",
            "Epoch 8/100\n",
            "422/422 [==============================] - 47s 112ms/step - loss: 0.0146 - accuracy: 0.9908 - val_loss: 0.0477 - val_accuracy: 0.9901\n",
            "Epoch 9/100\n",
            "422/422 [==============================] - 49s 116ms/step - loss: 0.0097 - accuracy: 0.9932 - val_loss: 0.0401 - val_accuracy: 0.9916\n",
            "Epoch 10/100\n",
            "422/422 [==============================] - 46s 110ms/step - loss: 0.0070 - accuracy: 0.9947 - val_loss: 0.0290 - val_accuracy: 0.9937\n",
            "Epoch 11/100\n",
            "422/422 [==============================] - 47s 110ms/step - loss: 0.0318 - accuracy: 0.9893 - val_loss: 0.0411 - val_accuracy: 0.9907\n",
            "Epoch 12/100\n",
            "422/422 [==============================] - 47s 112ms/step - loss: 0.0067 - accuracy: 0.9950 - val_loss: 0.0279 - val_accuracy: 0.9946\n",
            "Epoch 13/100\n",
            "422/422 [==============================] - 49s 115ms/step - loss: 0.0040 - accuracy: 0.9969 - val_loss: 0.0208 - val_accuracy: 0.9956\n",
            "Epoch 14/100\n",
            "422/422 [==============================] - 47s 110ms/step - loss: 0.0032 - accuracy: 0.9973 - val_loss: 0.0178 - val_accuracy: 0.9961\n",
            "Epoch 15/100\n",
            "422/422 [==============================] - 46s 109ms/step - loss: 0.0023 - accuracy: 0.9979 - val_loss: 0.0146 - val_accuracy: 0.9971\n",
            "Epoch 16/100\n",
            "422/422 [==============================] - 47s 110ms/step - loss: 0.0020 - accuracy: 0.9983 - val_loss: 0.0117 - val_accuracy: 0.9977\n",
            "Epoch 17/100\n",
            "422/422 [==============================] - 48s 113ms/step - loss: 0.0223 - accuracy: 0.9916 - val_loss: 0.0467 - val_accuracy: 0.9883\n",
            "Epoch 18/100\n",
            "422/422 [==============================] - 47s 112ms/step - loss: 0.0085 - accuracy: 0.9951 - val_loss: 0.0223 - val_accuracy: 0.9951\n",
            "Epoch 19/100\n",
            "422/422 [==============================] - 48s 113ms/step - loss: 0.0027 - accuracy: 0.9977 - val_loss: 0.0147 - val_accuracy: 0.9971\n",
            "Epoch 20/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 0.0022 - accuracy: 0.9982 - val_loss: 0.0144 - val_accuracy: 0.9973\n",
            "Epoch 21/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 0.0017 - accuracy: 0.9987 - val_loss: 0.0131 - val_accuracy: 0.9974\n",
            "Epoch 22/100\n",
            "422/422 [==============================] - 46s 110ms/step - loss: 0.0013 - accuracy: 0.9988 - val_loss: 0.0099 - val_accuracy: 0.9982\n",
            "Epoch 23/100\n",
            "422/422 [==============================] - 47s 110ms/step - loss: 0.0012 - accuracy: 0.9989 - val_loss: 0.0101 - val_accuracy: 0.9977\n",
            "Epoch 24/100\n",
            "422/422 [==============================] - 48s 113ms/step - loss: 0.0014 - accuracy: 0.9988 - val_loss: 0.0125 - val_accuracy: 0.9975\n",
            "Epoch 25/100\n",
            "422/422 [==============================] - 47s 110ms/step - loss: 0.0011 - accuracy: 0.9989 - val_loss: 0.0077 - val_accuracy: 0.9988\n",
            "Epoch 26/100\n",
            "422/422 [==============================] - 46s 109ms/step - loss: 0.0377 - accuracy: 0.9918 - val_loss: 0.0268 - val_accuracy: 0.9933\n",
            "Epoch 27/100\n",
            "422/422 [==============================] - 46s 110ms/step - loss: 0.0043 - accuracy: 0.9974 - val_loss: 0.0147 - val_accuracy: 0.9969\n",
            "Epoch 28/100\n",
            "422/422 [==============================] - 46s 110ms/step - loss: 0.0018 - accuracy: 0.9985 - val_loss: 0.0115 - val_accuracy: 0.9976\n",
            "Epoch 29/100\n",
            "422/422 [==============================] - 47s 110ms/step - loss: 0.0015 - accuracy: 0.9988 - val_loss: 0.0114 - val_accuracy: 0.9977\n",
            "Epoch 30/100\n",
            "422/422 [==============================] - 47s 112ms/step - loss: 0.0013 - accuracy: 0.9989 - val_loss: 0.0099 - val_accuracy: 0.9981\n",
            "Epoch 31/100\n",
            "422/422 [==============================] - 46s 110ms/step - loss: 0.0010 - accuracy: 0.9990 - val_loss: 0.0073 - val_accuracy: 0.9987\n",
            "Epoch 32/100\n",
            "422/422 [==============================] - 46s 109ms/step - loss: 9.9233e-04 - accuracy: 0.9991 - val_loss: 0.0096 - val_accuracy: 0.9983\n",
            "Epoch 33/100\n",
            "422/422 [==============================] - 47s 112ms/step - loss: 0.0010 - accuracy: 0.9991 - val_loss: 0.0091 - val_accuracy: 0.9986\n",
            "Epoch 34/100\n",
            "422/422 [==============================] - 46s 110ms/step - loss: 9.1738e-04 - accuracy: 0.9991 - val_loss: 0.0082 - val_accuracy: 0.9987\n",
            "Epoch 35/100\n",
            "422/422 [==============================] - 46s 110ms/step - loss: 8.7911e-04 - accuracy: 0.9991 - val_loss: 0.0079 - val_accuracy: 0.9987\n",
            "Epoch 36/100\n",
            "422/422 [==============================] - 47s 112ms/step - loss: 7.9355e-04 - accuracy: 0.9992 - val_loss: 0.0076 - val_accuracy: 0.9988\n",
            "Epoch 37/100\n",
            "422/422 [==============================] - 48s 113ms/step - loss: 8.6119e-04 - accuracy: 0.9992 - val_loss: 0.0069 - val_accuracy: 0.9988\n",
            "Epoch 38/100\n",
            "422/422 [==============================] - 47s 112ms/step - loss: 9.2523e-04 - accuracy: 0.9992 - val_loss: 0.0083 - val_accuracy: 0.9986\n",
            "Epoch 39/100\n",
            "422/422 [==============================] - 49s 117ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.0255 - val_accuracy: 0.9942\n",
            "Epoch 40/100\n",
            "422/422 [==============================] - 51s 120ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.0109 - val_accuracy: 0.9982\n",
            "Epoch 41/100\n",
            "422/422 [==============================] - 47s 112ms/step - loss: 0.0011 - accuracy: 0.9991 - val_loss: 0.0084 - val_accuracy: 0.9988\n",
            "Epoch 42/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 8.9296e-04 - accuracy: 0.9992 - val_loss: 0.0080 - val_accuracy: 0.9987\n",
            "Epoch 43/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 7.4042e-04 - accuracy: 0.9992 - val_loss: 0.0067 - val_accuracy: 0.9989\n",
            "Epoch 44/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 7.4661e-04 - accuracy: 0.9993 - val_loss: 0.0073 - val_accuracy: 0.9989\n",
            "Epoch 45/100\n",
            "422/422 [==============================] - 47s 110ms/step - loss: 6.6246e-04 - accuracy: 0.9994 - val_loss: 0.0064 - val_accuracy: 0.9989\n",
            "Epoch 46/100\n",
            "422/422 [==============================] - 52s 124ms/step - loss: 7.1458e-04 - accuracy: 0.9993 - val_loss: 0.0058 - val_accuracy: 0.9991\n",
            "Epoch 47/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 6.8479e-04 - accuracy: 0.9994 - val_loss: 0.0067 - val_accuracy: 0.9989\n",
            "Epoch 48/100\n",
            "422/422 [==============================] - 49s 116ms/step - loss: 6.8750e-04 - accuracy: 0.9994 - val_loss: 0.0076 - val_accuracy: 0.9991\n",
            "Epoch 49/100\n",
            "422/422 [==============================] - 48s 113ms/step - loss: 7.1769e-04 - accuracy: 0.9994 - val_loss: 0.0073 - val_accuracy: 0.9990\n",
            "Epoch 50/100\n",
            "422/422 [==============================] - 48s 113ms/step - loss: 7.7461e-04 - accuracy: 0.9994 - val_loss: 0.0068 - val_accuracy: 0.9991\n",
            "Epoch 51/100\n",
            "422/422 [==============================] - 47s 112ms/step - loss: 9.6562e-04 - accuracy: 0.9993 - val_loss: 0.0102 - val_accuracy: 0.9986\n",
            "Epoch 52/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0265 - val_accuracy: 0.9943\n",
            "Epoch 53/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.0110 - val_accuracy: 0.9984\n",
            "Epoch 54/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 8.7381e-04 - accuracy: 0.9992 - val_loss: 0.0103 - val_accuracy: 0.9985\n",
            "Epoch 55/100\n",
            "422/422 [==============================] - 47s 110ms/step - loss: 7.3637e-04 - accuracy: 0.9992 - val_loss: 0.0076 - val_accuracy: 0.9989\n",
            "Epoch 56/100\n",
            "422/422 [==============================] - 47s 110ms/step - loss: 6.6929e-04 - accuracy: 0.9993 - val_loss: 0.0080 - val_accuracy: 0.9990\n",
            "Epoch 57/100\n",
            "422/422 [==============================] - 46s 110ms/step - loss: 5.9293e-04 - accuracy: 0.9994 - val_loss: 0.0079 - val_accuracy: 0.9990\n",
            "Epoch 58/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 6.0773e-04 - accuracy: 0.9994 - val_loss: 0.0081 - val_accuracy: 0.9990\n",
            "Epoch 59/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 6.0254e-04 - accuracy: 0.9994 - val_loss: 0.0081 - val_accuracy: 0.9990\n",
            "Epoch 60/100\n",
            "422/422 [==============================] - 46s 110ms/step - loss: 6.3121e-04 - accuracy: 0.9994 - val_loss: 0.0089 - val_accuracy: 0.9990\n",
            "Epoch 61/100\n",
            "422/422 [==============================] - 47s 110ms/step - loss: 6.1799e-04 - accuracy: 0.9994 - val_loss: 0.0079 - val_accuracy: 0.9990\n",
            "Epoch 62/100\n",
            "422/422 [==============================] - 46s 109ms/step - loss: 6.3391e-04 - accuracy: 0.9994 - val_loss: 0.0085 - val_accuracy: 0.9990\n",
            "Epoch 63/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 6.5527e-04 - accuracy: 0.9994 - val_loss: 0.0088 - val_accuracy: 0.9990\n",
            "Epoch 64/100\n",
            "422/422 [==============================] - 48s 113ms/step - loss: 6.0509e-04 - accuracy: 0.9994 - val_loss: 0.0076 - val_accuracy: 0.9991\n",
            "Epoch 65/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 5.3752e-04 - accuracy: 0.9994 - val_loss: 0.0071 - val_accuracy: 0.9991\n",
            "Epoch 66/100\n",
            "422/422 [==============================] - 47s 112ms/step - loss: 5.7639e-04 - accuracy: 0.9994 - val_loss: 0.0089 - val_accuracy: 0.9990\n",
            "Epoch 67/100\n",
            "422/422 [==============================] - 47s 110ms/step - loss: 6.5329e-04 - accuracy: 0.9994 - val_loss: 0.0078 - val_accuracy: 0.9991\n",
            "Epoch 68/100\n",
            "422/422 [==============================] - 47s 110ms/step - loss: 0.0019 - accuracy: 0.9991 - val_loss: 0.0200 - val_accuracy: 0.9966\n",
            "Epoch 69/100\n",
            "422/422 [==============================] - 46s 110ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0089 - val_accuracy: 0.9987\n",
            "Epoch 70/100\n",
            "422/422 [==============================] - 47s 112ms/step - loss: 6.7254e-04 - accuracy: 0.9993 - val_loss: 0.0072 - val_accuracy: 0.9989\n",
            "Epoch 71/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 0.0017 - accuracy: 0.9987 - val_loss: 0.0074 - val_accuracy: 0.9989\n",
            "Epoch 72/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 5.4901e-04 - accuracy: 0.9994 - val_loss: 0.0075 - val_accuracy: 0.9989\n",
            "Epoch 73/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 5.1452e-04 - accuracy: 0.9994 - val_loss: 0.0066 - val_accuracy: 0.9990\n",
            "Epoch 74/100\n",
            "422/422 [==============================] - 47s 112ms/step - loss: 4.8607e-04 - accuracy: 0.9994 - val_loss: 0.0072 - val_accuracy: 0.9990\n",
            "Epoch 75/100\n",
            "422/422 [==============================] - 46s 110ms/step - loss: 4.6515e-04 - accuracy: 0.9994 - val_loss: 0.0070 - val_accuracy: 0.9991\n",
            "Epoch 76/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 4.7458e-04 - accuracy: 0.9994 - val_loss: 0.0066 - val_accuracy: 0.9991\n",
            "Epoch 77/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 4.7084e-04 - accuracy: 0.9995 - val_loss: 0.0068 - val_accuracy: 0.9991\n",
            "Epoch 78/100\n",
            "422/422 [==============================] - 47s 112ms/step - loss: 4.7173e-04 - accuracy: 0.9994 - val_loss: 0.0074 - val_accuracy: 0.9991\n",
            "Epoch 79/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 4.4458e-04 - accuracy: 0.9995 - val_loss: 0.0070 - val_accuracy: 0.9991\n",
            "Epoch 80/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 4.7955e-04 - accuracy: 0.9995 - val_loss: 0.0069 - val_accuracy: 0.9991\n",
            "Epoch 81/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 4.3951e-04 - accuracy: 0.9995 - val_loss: 0.0067 - val_accuracy: 0.9991\n",
            "Epoch 82/100\n",
            "422/422 [==============================] - 46s 110ms/step - loss: 4.2533e-04 - accuracy: 0.9995 - val_loss: 0.0072 - val_accuracy: 0.9991\n",
            "Epoch 83/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 4.9913e-04 - accuracy: 0.9995 - val_loss: 0.0075 - val_accuracy: 0.9991\n",
            "Epoch 84/100\n",
            "422/422 [==============================] - 46s 110ms/step - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.0113 - val_accuracy: 0.9982\n",
            "Epoch 85/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 0.0014 - accuracy: 0.9992 - val_loss: 0.0096 - val_accuracy: 0.9989\n",
            "Epoch 86/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 8.8217e-04 - accuracy: 0.9994 - val_loss: 0.0089 - val_accuracy: 0.9990\n",
            "Epoch 87/100\n",
            "422/422 [==============================] - 46s 110ms/step - loss: 8.2826e-04 - accuracy: 0.9994 - val_loss: 0.0096 - val_accuracy: 0.9990\n",
            "Epoch 88/100\n",
            "422/422 [==============================] - 47s 110ms/step - loss: 8.0563e-04 - accuracy: 0.9994 - val_loss: 0.0091 - val_accuracy: 0.9990\n",
            "Epoch 89/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 8.6715e-04 - accuracy: 0.9994 - val_loss: 0.0096 - val_accuracy: 0.9990\n",
            "Epoch 90/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 8.2835e-04 - accuracy: 0.9994 - val_loss: 0.0092 - val_accuracy: 0.9990\n",
            "Epoch 91/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 8.7796e-04 - accuracy: 0.9994 - val_loss: 0.0090 - val_accuracy: 0.9990\n",
            "Epoch 92/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 6.3910e-04 - accuracy: 0.9994 - val_loss: 0.0080 - val_accuracy: 0.9991\n",
            "Epoch 93/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 5.1946e-04 - accuracy: 0.9994 - val_loss: 0.0075 - val_accuracy: 0.9991\n",
            "Epoch 94/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 4.8680e-04 - accuracy: 0.9995 - val_loss: 0.0077 - val_accuracy: 0.9991\n",
            "Epoch 95/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 5.1425e-04 - accuracy: 0.9995 - val_loss: 0.0078 - val_accuracy: 0.9991\n",
            "Epoch 96/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 5.5641e-04 - accuracy: 0.9994 - val_loss: 0.0082 - val_accuracy: 0.9991\n",
            "Epoch 97/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 5.4936e-04 - accuracy: 0.9994 - val_loss: 0.0081 - val_accuracy: 0.9991\n",
            "Epoch 98/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 5.4472e-04 - accuracy: 0.9994 - val_loss: 0.0080 - val_accuracy: 0.9991\n",
            "Epoch 99/100\n",
            "422/422 [==============================] - 46s 109ms/step - loss: 5.5405e-04 - accuracy: 0.9994 - val_loss: 0.0078 - val_accuracy: 0.9991\n",
            "Epoch 100/100\n",
            "422/422 [==============================] - 47s 111ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.0124 - val_accuracy: 0.9978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "422/422 [==============================] - 117s 257ms/step - loss: 4.3985 - accuracy: 0.3642 - val_loss: 1.1624 - val_accuracy: 0.6895\n",
            "Epoch 2/100\n",
            "422/422 [==============================] - 109s 259ms/step - loss: 0.8113 - accuracy: 0.7765 - val_loss: 0.4554 - val_accuracy: 0.8355\n",
            "Epoch 3/100\n",
            "422/422 [==============================] - 108s 255ms/step - loss: 0.3369 - accuracy: 0.8919 - val_loss: 0.2612 - val_accuracy: 0.9352\n",
            "Epoch 4/100\n",
            "422/422 [==============================] - 107s 254ms/step - loss: 0.1763 - accuracy: 0.9455 - val_loss: 0.1919 - val_accuracy: 0.9562\n",
            "Epoch 5/100\n",
            "422/422 [==============================] - 107s 254ms/step - loss: 0.1319 - accuracy: 0.9589 - val_loss: 0.1554 - val_accuracy: 0.9656\n",
            "Epoch 6/100\n",
            "422/422 [==============================] - 106s 252ms/step - loss: 0.0831 - accuracy: 0.9690 - val_loss: 0.1165 - val_accuracy: 0.9745\n",
            "Epoch 7/100\n",
            "422/422 [==============================] - 107s 254ms/step - loss: 0.0555 - accuracy: 0.9760 - val_loss: 0.0957 - val_accuracy: 0.9790\n",
            "Epoch 8/100\n",
            "422/422 [==============================] - 108s 256ms/step - loss: 0.0390 - accuracy: 0.9808 - val_loss: 0.0733 - val_accuracy: 0.9835\n",
            "Epoch 9/100\n",
            "422/422 [==============================] - 107s 253ms/step - loss: 0.0283 - accuracy: 0.9846 - val_loss: 0.0624 - val_accuracy: 0.9860\n",
            "Epoch 10/100\n",
            "422/422 [==============================] - 107s 254ms/step - loss: 0.0233 - accuracy: 0.9865 - val_loss: 0.0546 - val_accuracy: 0.9882\n",
            "Epoch 11/100\n",
            "422/422 [==============================] - 108s 256ms/step - loss: 0.0192 - accuracy: 0.9885 - val_loss: 0.0487 - val_accuracy: 0.9887\n",
            "Epoch 12/100\n",
            "422/422 [==============================] - 109s 258ms/step - loss: 0.0182 - accuracy: 0.9895 - val_loss: 0.0406 - val_accuracy: 0.9913\n",
            "Epoch 13/100\n",
            "422/422 [==============================] - 119s 281ms/step - loss: 0.0139 - accuracy: 0.9914 - val_loss: 0.0401 - val_accuracy: 0.9914\n",
            "Epoch 14/100\n",
            "422/422 [==============================] - 108s 257ms/step - loss: 0.0112 - accuracy: 0.9926 - val_loss: 0.0368 - val_accuracy: 0.9921\n",
            "Epoch 15/100\n",
            "422/422 [==============================] - 108s 257ms/step - loss: 0.0107 - accuracy: 0.9930 - val_loss: 0.0343 - val_accuracy: 0.9926\n",
            "Epoch 16/100\n",
            "422/422 [==============================] - 108s 256ms/step - loss: 0.0109 - accuracy: 0.9932 - val_loss: 0.0435 - val_accuracy: 0.9895\n",
            "Epoch 17/100\n",
            "422/422 [==============================] - 110s 260ms/step - loss: 0.0132 - accuracy: 0.9929 - val_loss: 0.0321 - val_accuracy: 0.9936\n",
            "Epoch 18/100\n",
            "422/422 [==============================] - 108s 256ms/step - loss: 0.0079 - accuracy: 0.9948 - val_loss: 0.0307 - val_accuracy: 0.9940\n",
            "Epoch 19/100\n",
            "422/422 [==============================] - 107s 253ms/step - loss: 0.0063 - accuracy: 0.9954 - val_loss: 0.0231 - val_accuracy: 0.9954\n",
            "Epoch 20/100\n",
            "422/422 [==============================] - 108s 255ms/step - loss: 0.0055 - accuracy: 0.9959 - val_loss: 0.0246 - val_accuracy: 0.9953\n",
            "Epoch 21/100\n",
            "422/422 [==============================] - 107s 254ms/step - loss: 0.0042 - accuracy: 0.9968 - val_loss: 0.0200 - val_accuracy: 0.9961\n",
            "Epoch 22/100\n",
            "422/422 [==============================] - 107s 255ms/step - loss: 0.0046 - accuracy: 0.9967 - val_loss: 0.0216 - val_accuracy: 0.9954\n",
            "Epoch 23/100\n",
            "422/422 [==============================] - 108s 256ms/step - loss: 0.0103 - accuracy: 0.9955 - val_loss: 0.0254 - val_accuracy: 0.9945\n",
            "Epoch 24/100\n",
            "422/422 [==============================] - 108s 256ms/step - loss: 0.0099 - accuracy: 0.9951 - val_loss: 0.0202 - val_accuracy: 0.9958\n",
            "Epoch 25/100\n",
            "422/422 [==============================] - 110s 262ms/step - loss: 0.0041 - accuracy: 0.9970 - val_loss: 0.0172 - val_accuracy: 0.9966\n",
            "Epoch 26/100\n",
            "422/422 [==============================] - 114s 270ms/step - loss: 0.0034 - accuracy: 0.9974 - val_loss: 0.0184 - val_accuracy: 0.9967\n",
            "Epoch 27/100\n",
            "422/422 [==============================] - 112s 265ms/step - loss: 0.0040 - accuracy: 0.9971 - val_loss: 0.0159 - val_accuracy: 0.9970\n",
            "Epoch 28/100\n",
            "422/422 [==============================] - 108s 256ms/step - loss: 0.0040 - accuracy: 0.9973 - val_loss: 0.0159 - val_accuracy: 0.9969\n",
            "Epoch 29/100\n",
            "422/422 [==============================] - 110s 261ms/step - loss: 0.0032 - accuracy: 0.9975 - val_loss: 0.0138 - val_accuracy: 0.9974\n",
            "Epoch 30/100\n",
            "422/422 [==============================] - 111s 263ms/step - loss: 0.0095 - accuracy: 0.9953 - val_loss: 0.0182 - val_accuracy: 0.9964\n",
            "Epoch 31/100\n",
            "422/422 [==============================] - 111s 263ms/step - loss: 0.0038 - accuracy: 0.9969 - val_loss: 0.0137 - val_accuracy: 0.9969\n",
            "Epoch 32/100\n",
            "422/422 [==============================] - 110s 260ms/step - loss: 0.0027 - accuracy: 0.9977 - val_loss: 0.0127 - val_accuracy: 0.9975\n",
            "Epoch 33/100\n",
            "422/422 [==============================] - 110s 260ms/step - loss: 0.0023 - accuracy: 0.9980 - val_loss: 0.0129 - val_accuracy: 0.9974\n",
            "Epoch 34/100\n",
            "422/422 [==============================] - 108s 255ms/step - loss: 0.0021 - accuracy: 0.9982 - val_loss: 0.0111 - val_accuracy: 0.9975\n",
            "Epoch 35/100\n",
            "422/422 [==============================] - 108s 257ms/step - loss: 0.0023 - accuracy: 0.9982 - val_loss: 0.0120 - val_accuracy: 0.9977\n",
            "Epoch 36/100\n",
            "422/422 [==============================] - 110s 262ms/step - loss: 0.0018 - accuracy: 0.9983 - val_loss: 0.0090 - val_accuracy: 0.9980\n",
            "Epoch 37/100\n",
            "422/422 [==============================] - 107s 254ms/step - loss: 0.0017 - accuracy: 0.9984 - val_loss: 0.0111 - val_accuracy: 0.9978\n",
            "Epoch 38/100\n",
            "422/422 [==============================] - 111s 264ms/step - loss: 0.0029 - accuracy: 0.9981 - val_loss: 0.0135 - val_accuracy: 0.9979\n",
            "Epoch 39/100\n",
            "422/422 [==============================] - 113s 268ms/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 0.0105 - val_accuracy: 0.9978\n",
            "Epoch 40/100\n",
            "422/422 [==============================] - 108s 257ms/step - loss: 0.0030 - accuracy: 0.9978 - val_loss: 0.0093 - val_accuracy: 0.9978\n",
            "Epoch 41/100\n",
            "422/422 [==============================] - 108s 256ms/step - loss: 0.0022 - accuracy: 0.9984 - val_loss: 0.0093 - val_accuracy: 0.9983\n",
            "Epoch 42/100\n",
            "422/422 [==============================] - 108s 255ms/step - loss: 0.0016 - accuracy: 0.9986 - val_loss: 0.0094 - val_accuracy: 0.9980\n",
            "Epoch 43/100\n",
            "422/422 [==============================] - 109s 257ms/step - loss: 0.0014 - accuracy: 0.9987 - val_loss: 0.0088 - val_accuracy: 0.9984\n",
            "Epoch 44/100\n",
            "422/422 [==============================] - 108s 256ms/step - loss: 0.0014 - accuracy: 0.9986 - val_loss: 0.0081 - val_accuracy: 0.9983\n",
            "Epoch 45/100\n",
            "422/422 [==============================] - 110s 261ms/step - loss: 0.0017 - accuracy: 0.9987 - val_loss: 0.0082 - val_accuracy: 0.9984\n",
            "Epoch 46/100\n",
            "422/422 [==============================] - 107s 254ms/step - loss: 0.0014 - accuracy: 0.9987 - val_loss: 0.0082 - val_accuracy: 0.9985\n",
            "Epoch 47/100\n",
            "422/422 [==============================] - 108s 255ms/step - loss: 0.0014 - accuracy: 0.9988 - val_loss: 0.0087 - val_accuracy: 0.9986\n",
            "Epoch 48/100\n",
            "422/422 [==============================] - 108s 256ms/step - loss: 0.0028 - accuracy: 0.9982 - val_loss: 0.0104 - val_accuracy: 0.9985\n",
            "Epoch 49/100\n",
            "422/422 [==============================] - 107s 254ms/step - loss: 0.0018 - accuracy: 0.9987 - val_loss: 0.0101 - val_accuracy: 0.9984\n",
            "Epoch 50/100\n",
            "422/422 [==============================] - 107s 253ms/step - loss: 0.0034 - accuracy: 0.9984 - val_loss: 0.0088 - val_accuracy: 0.9986\n",
            "Epoch 51/100\n",
            "422/422 [==============================] - 109s 259ms/step - loss: 0.0040 - accuracy: 0.9981 - val_loss: 0.0083 - val_accuracy: 0.9986\n",
            "Epoch 52/100\n",
            "422/422 [==============================] - 110s 262ms/step - loss: 0.0019 - accuracy: 0.9987 - val_loss: 0.0079 - val_accuracy: 0.9986\n",
            "Epoch 53/100\n",
            "422/422 [==============================] - 108s 257ms/step - loss: 0.0013 - accuracy: 0.9989 - val_loss: 0.0090 - val_accuracy: 0.9986\n",
            "Epoch 54/100\n",
            "422/422 [==============================] - 108s 256ms/step - loss: 0.0014 - accuracy: 0.9989 - val_loss: 0.0076 - val_accuracy: 0.9987\n",
            "Epoch 55/100\n",
            "422/422 [==============================] - 108s 255ms/step - loss: 0.0011 - accuracy: 0.9990 - val_loss: 0.0074 - val_accuracy: 0.9985\n",
            "Epoch 56/100\n",
            "422/422 [==============================] - 110s 262ms/step - loss: 0.0018 - accuracy: 0.9989 - val_loss: 0.0073 - val_accuracy: 0.9989\n",
            "Epoch 57/100\n",
            "422/422 [==============================] - 108s 256ms/step - loss: 0.0016 - accuracy: 0.9989 - val_loss: 0.0082 - val_accuracy: 0.9984\n",
            "Epoch 58/100\n",
            "422/422 [==============================] - 109s 257ms/step - loss: 0.0016 - accuracy: 0.9989 - val_loss: 0.0061 - val_accuracy: 0.9989\n",
            "Epoch 59/100\n",
            "422/422 [==============================] - 108s 256ms/step - loss: 0.0013 - accuracy: 0.9990 - val_loss: 0.0067 - val_accuracy: 0.9989\n",
            "Epoch 60/100\n",
            "422/422 [==============================] - 108s 255ms/step - loss: 0.0010 - accuracy: 0.9991 - val_loss: 0.0067 - val_accuracy: 0.9989\n",
            "Epoch 61/100\n",
            "422/422 [==============================] - 107s 253ms/step - loss: 9.6160e-04 - accuracy: 0.9991 - val_loss: 0.0065 - val_accuracy: 0.9989\n",
            "Epoch 62/100\n",
            "422/422 [==============================] - 107s 255ms/step - loss: 9.5706e-04 - accuracy: 0.9991 - val_loss: 0.0066 - val_accuracy: 0.9989\n",
            "Epoch 63/100\n",
            "422/422 [==============================] - 109s 258ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 0.0060 - val_accuracy: 0.9988\n",
            "Epoch 64/100\n",
            "422/422 [==============================] - 107s 253ms/step - loss: 0.0016 - accuracy: 0.9989 - val_loss: 0.0070 - val_accuracy: 0.9988\n",
            "Epoch 65/100\n",
            "422/422 [==============================] - 108s 255ms/step - loss: 0.0010 - accuracy: 0.9991 - val_loss: 0.0073 - val_accuracy: 0.9989\n",
            "Epoch 66/100\n",
            "422/422 [==============================] - 108s 256ms/step - loss: 0.0012 - accuracy: 0.9990 - val_loss: 0.0086 - val_accuracy: 0.9987\n",
            "Epoch 67/100\n",
            "422/422 [==============================] - 108s 257ms/step - loss: 0.0011 - accuracy: 0.9990 - val_loss: 0.0067 - val_accuracy: 0.9988\n",
            "Epoch 68/100\n",
            "422/422 [==============================] - 109s 258ms/step - loss: 0.0014 - accuracy: 0.9990 - val_loss: 0.0085 - val_accuracy: 0.9988\n",
            "Epoch 69/100\n",
            "422/422 [==============================] - 110s 261ms/step - loss: 0.0016 - accuracy: 0.9990 - val_loss: 0.0066 - val_accuracy: 0.9989\n",
            "Epoch 70/100\n",
            "422/422 [==============================] - 108s 257ms/step - loss: 9.6486e-04 - accuracy: 0.9991 - val_loss: 0.0074 - val_accuracy: 0.9989\n",
            "Epoch 71/100\n",
            "422/422 [==============================] - 110s 261ms/step - loss: 9.8150e-04 - accuracy: 0.9992 - val_loss: 0.0074 - val_accuracy: 0.9989\n",
            "Epoch 72/100\n",
            "422/422 [==============================] - 113s 268ms/step - loss: 0.0012 - accuracy: 0.9991 - val_loss: 0.0075 - val_accuracy: 0.9989\n",
            "Epoch 73/100\n",
            "422/422 [==============================] - 113s 268ms/step - loss: 8.4773e-04 - accuracy: 0.9992 - val_loss: 0.0067 - val_accuracy: 0.9989\n",
            "Epoch 74/100\n",
            "422/422 [==============================] - 109s 258ms/step - loss: 7.6763e-04 - accuracy: 0.9993 - val_loss: 0.0054 - val_accuracy: 0.9989\n",
            "Epoch 75/100\n",
            "422/422 [==============================] - 110s 261ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 0.0072 - val_accuracy: 0.9989\n",
            "Epoch 76/100\n",
            "422/422 [==============================] - 108s 257ms/step - loss: 0.0013 - accuracy: 0.9991 - val_loss: 0.0063 - val_accuracy: 0.9988\n",
            "Epoch 77/100\n",
            "422/422 [==============================] - 110s 261ms/step - loss: 0.0011 - accuracy: 0.9992 - val_loss: 0.0066 - val_accuracy: 0.9989\n",
            "Epoch 78/100\n",
            "422/422 [==============================] - 110s 261ms/step - loss: 9.0701e-04 - accuracy: 0.9992 - val_loss: 0.0069 - val_accuracy: 0.9989\n",
            "Epoch 79/100\n",
            "422/422 [==============================] - 107s 253ms/step - loss: 8.9869e-04 - accuracy: 0.9992 - val_loss: 0.0078 - val_accuracy: 0.9988\n",
            "Epoch 80/100\n",
            "422/422 [==============================] - 109s 258ms/step - loss: 8.7693e-04 - accuracy: 0.9993 - val_loss: 0.0066 - val_accuracy: 0.9989\n",
            "Epoch 81/100\n",
            "422/422 [==============================] - 108s 255ms/step - loss: 0.0011 - accuracy: 0.9992 - val_loss: 0.0067 - val_accuracy: 0.9987\n",
            "Epoch 82/100\n",
            "422/422 [==============================] - 110s 259ms/step - loss: 0.0013 - accuracy: 0.9990 - val_loss: 0.0073 - val_accuracy: 0.9988\n",
            "Epoch 83/100\n",
            "422/422 [==============================] - 106s 251ms/step - loss: 0.0013 - accuracy: 0.9991 - val_loss: 0.0068 - val_accuracy: 0.9989\n",
            "Epoch 84/100\n",
            "422/422 [==============================] - 108s 255ms/step - loss: 8.5859e-04 - accuracy: 0.9993 - val_loss: 0.0078 - val_accuracy: 0.9989\n",
            "Epoch 85/100\n",
            "422/422 [==============================] - 107s 254ms/step - loss: 8.1688e-04 - accuracy: 0.9993 - val_loss: 0.0073 - val_accuracy: 0.9989\n",
            "Epoch 86/100\n",
            "422/422 [==============================] - 111s 262ms/step - loss: 7.6800e-04 - accuracy: 0.9993 - val_loss: 0.0071 - val_accuracy: 0.9989\n",
            "Epoch 87/100\n",
            "422/422 [==============================] - 108s 257ms/step - loss: 7.9466e-04 - accuracy: 0.9992 - val_loss: 0.0072 - val_accuracy: 0.9989\n",
            "Epoch 88/100\n",
            "422/422 [==============================] - 108s 257ms/step - loss: 0.0011 - accuracy: 0.9993 - val_loss: 0.0084 - val_accuracy: 0.9987\n",
            "Epoch 89/100\n",
            "422/422 [==============================] - 108s 256ms/step - loss: 0.0012 - accuracy: 0.9992 - val_loss: 0.0073 - val_accuracy: 0.9989\n",
            "Epoch 90/100\n",
            "422/422 [==============================] - 107s 255ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 0.0081 - val_accuracy: 0.9989\n",
            "Epoch 91/100\n",
            "422/422 [==============================] - 107s 254ms/step - loss: 7.4704e-04 - accuracy: 0.9993 - val_loss: 0.0078 - val_accuracy: 0.9989\n",
            "Epoch 92/100\n",
            "422/422 [==============================] - 107s 254ms/step - loss: 6.5524e-04 - accuracy: 0.9993 - val_loss: 0.0074 - val_accuracy: 0.9990\n",
            "Epoch 93/100\n",
            "422/422 [==============================] - 109s 257ms/step - loss: 7.2093e-04 - accuracy: 0.9993 - val_loss: 0.0079 - val_accuracy: 0.9989\n",
            "Epoch 94/100\n",
            "422/422 [==============================] - 111s 264ms/step - loss: 7.7467e-04 - accuracy: 0.9993 - val_loss: 0.0076 - val_accuracy: 0.9989\n",
            "Epoch 95/100\n",
            "422/422 [==============================] - 109s 259ms/step - loss: 7.1931e-04 - accuracy: 0.9993 - val_loss: 0.0062 - val_accuracy: 0.9989\n",
            "Epoch 96/100\n",
            "422/422 [==============================] - 109s 258ms/step - loss: 8.0290e-04 - accuracy: 0.9993 - val_loss: 0.0067 - val_accuracy: 0.9991\n",
            "Epoch 97/100\n",
            "422/422 [==============================] - 112s 266ms/step - loss: 9.0523e-04 - accuracy: 0.9993 - val_loss: 0.0081 - val_accuracy: 0.9989\n",
            "Epoch 98/100\n",
            "422/422 [==============================] - 114s 270ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0075 - val_accuracy: 0.9988\n",
            "Epoch 99/100\n",
            "422/422 [==============================] - 111s 263ms/step - loss: 0.0012 - accuracy: 0.9991 - val_loss: 0.0073 - val_accuracy: 0.9989\n",
            "Epoch 100/100\n",
            "422/422 [==============================] - 110s 260ms/step - loss: 9.2003e-04 - accuracy: 0.9992 - val_loss: 0.0071 - val_accuracy: 0.9989\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, TimeDistributed, Dense\n",
        "\n",
        "# Define model architecture\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=n_words + 2, output_dim=50, input_length=maxlen, mask_zero=True))\n",
        "model.add(Bidirectional(LSTM(units=100, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(n_tags, activation=\"softmax\")))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.1, class_weight=class_weights_dict)\n",
        "\n",
        "# Save the model\n",
        "model.save('pos_model.h5')\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, TimeDistributed, Dense, Dropout\n",
        "\n",
        "# Define model architecture\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=n_words + 2, output_dim=50, input_length=maxlen, mask_zero=True))\n",
        "model.add(Bidirectional(LSTM(units=100, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)))\n",
        "model.add(TimeDistributed(Dense(n_tags, activation=\"softmax\")))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with class weights\n",
        "history = model.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.1, class_weight=class_weights_dict)\n",
        "\n",
        "# Save the model\n",
        "model.save('pos_model_improved.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gx5WAOCFuse2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7q-1fequsaw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the model\n",
        "model = load_model('pos_model_improved.h5')\n",
        "\n",
        "def predict_with_confidence(sentence):\n",
        "    words = sentence.split()\n",
        "    word_indices = [word2idx.get(word, word2idx[\"UNK\"]) for word in words]\n",
        "    word_indices_padded = pad_sequences([word_indices], maxlen=maxlen, padding='post')\n",
        "    predictions = model.predict(word_indices_padded)\n",
        "\n",
        "    predicted_tags = []\n",
        "    confidence_scores = []\n",
        "\n",
        "    for pred in predictions[0]:\n",
        "        tag_idx = np.argmax(pred)\n",
        "        predicted_tags.append(idx2tag[tag_idx])\n",
        "        confidence_scores.append(pred[tag_idx])\n",
        "\n",
        "    return predicted_tags[:len(words)], confidence_scores[:len(words)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8GRjhQPusTN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53d8755d-81d2-4108-893f-cca96cb53d18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 866ms/step\n",
            "Predicted Tags: ['N', 'CONJ', 'N', 'N']\n",
            "Confidence Scores: [0.99997276, 0.94958043, 0.99993557, 0.99992865]\n"
          ]
        }
      ],
      "source": [
        "sentence = \"Amosi we munaanie Bibilia\"\n",
        "predicted_tags, confidence_scores = predict_with_confidence(sentence)\n",
        "print(\"Predicted Tags:\", predicted_tags)\n",
        "print(\"Confidence Scores:\", confidence_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_CQ49kLOQC3",
        "outputId": "0cab2dac-9368-4472-b324-9a8a579d73da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "422/422 [==============================] - 120s 263ms/step - loss: 4.5913 - accuracy: 0.3488 - val_loss: 1.3039 - val_accuracy: 0.6511\n",
            "Epoch 2/50\n",
            "422/422 [==============================] - 108s 257ms/step - loss: 1.0368 - accuracy: 0.7486 - val_loss: 0.5776 - val_accuracy: 0.8065\n",
            "Epoch 3/50\n",
            "422/422 [==============================] - 111s 264ms/step - loss: 0.4125 - accuracy: 0.8706 - val_loss: 0.3154 - val_accuracy: 0.9207\n",
            "Epoch 4/50\n",
            "422/422 [==============================] - 107s 253ms/step - loss: 0.2281 - accuracy: 0.9323 - val_loss: 0.2211 - val_accuracy: 0.9500\n",
            "Epoch 5/50\n",
            "422/422 [==============================] - 106s 252ms/step - loss: 0.1335 - accuracy: 0.9565 - val_loss: 0.1546 - val_accuracy: 0.9666\n",
            "Epoch 6/50\n",
            "422/422 [==============================] - 107s 253ms/step - loss: 0.0860 - accuracy: 0.9681 - val_loss: 0.1244 - val_accuracy: 0.9729\n",
            "Epoch 7/50\n",
            "422/422 [==============================] - 109s 258ms/step - loss: 0.0603 - accuracy: 0.9746 - val_loss: 0.0990 - val_accuracy: 0.9786\n",
            "Epoch 8/50\n",
            "422/422 [==============================] - 109s 258ms/step - loss: 0.0445 - accuracy: 0.9794 - val_loss: 0.0828 - val_accuracy: 0.9819\n",
            "Epoch 9/50\n",
            "422/422 [==============================] - 110s 260ms/step - loss: 0.0385 - accuracy: 0.9821 - val_loss: 0.0725 - val_accuracy: 0.9851\n",
            "Epoch 10/50\n",
            "422/422 [==============================] - 109s 258ms/step - loss: 0.0252 - accuracy: 0.9859 - val_loss: 0.0667 - val_accuracy: 0.9866\n",
            "Epoch 11/50\n",
            "422/422 [==============================] - 111s 264ms/step - loss: 0.0206 - accuracy: 0.9878 - val_loss: 0.0585 - val_accuracy: 0.9881\n",
            "Epoch 12/50\n",
            "422/422 [==============================] - 110s 261ms/step - loss: 0.0197 - accuracy: 0.9888 - val_loss: 0.0495 - val_accuracy: 0.9903\n",
            "Epoch 13/50\n",
            "422/422 [==============================] - 112s 267ms/step - loss: 0.0148 - accuracy: 0.9905 - val_loss: 0.0463 - val_accuracy: 0.9910\n",
            "Epoch 14/50\n",
            "422/422 [==============================] - 115s 272ms/step - loss: 0.0112 - accuracy: 0.9923 - val_loss: 0.0403 - val_accuracy: 0.9919\n",
            "Epoch 15/50\n",
            "422/422 [==============================] - 113s 267ms/step - loss: 0.0120 - accuracy: 0.9925 - val_loss: 0.0478 - val_accuracy: 0.9894\n",
            "Epoch 16/50\n",
            "422/422 [==============================] - 114s 271ms/step - loss: 0.0468 - accuracy: 0.9860 - val_loss: 0.0437 - val_accuracy: 0.9909\n",
            "Epoch 17/50\n",
            "422/422 [==============================] - 112s 265ms/step - loss: 0.0121 - accuracy: 0.9924 - val_loss: 0.0364 - val_accuracy: 0.9926\n",
            "Epoch 18/50\n",
            "422/422 [==============================] - 117s 277ms/step - loss: 0.0087 - accuracy: 0.9939 - val_loss: 0.0311 - val_accuracy: 0.9936\n",
            "Epoch 19/50\n",
            "422/422 [==============================] - 110s 260ms/step - loss: 0.0069 - accuracy: 0.9949 - val_loss: 0.0289 - val_accuracy: 0.9942\n",
            "Epoch 20/50\n",
            "422/422 [==============================] - 109s 259ms/step - loss: 0.0059 - accuracy: 0.9955 - val_loss: 0.0248 - val_accuracy: 0.9948\n",
            "Epoch 21/50\n",
            "422/422 [==============================] - 110s 262ms/step - loss: 0.0056 - accuracy: 0.9959 - val_loss: 0.0251 - val_accuracy: 0.9950\n",
            "Epoch 22/50\n",
            "422/422 [==============================] - 110s 260ms/step - loss: 0.0052 - accuracy: 0.9957 - val_loss: 0.0302 - val_accuracy: 0.9947\n",
            "Epoch 23/50\n",
            "422/422 [==============================] - 108s 255ms/step - loss: 0.0049 - accuracy: 0.9960 - val_loss: 0.0218 - val_accuracy: 0.9959\n",
            "Epoch 24/50\n",
            "422/422 [==============================] - 110s 262ms/step - loss: 0.0070 - accuracy: 0.9957 - val_loss: 0.0238 - val_accuracy: 0.9957\n",
            "Epoch 25/50\n",
            "422/422 [==============================] - 109s 258ms/step - loss: 0.0051 - accuracy: 0.9963 - val_loss: 0.0242 - val_accuracy: 0.9956\n",
            "Epoch 26/50\n",
            "422/422 [==============================] - 108s 255ms/step - loss: 0.0043 - accuracy: 0.9970 - val_loss: 0.0237 - val_accuracy: 0.9957\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define model architecture\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=n_words + 2, output_dim=50, input_length=maxlen, mask_zero=True))\n",
        "model.add(Bidirectional(LSTM(units=100, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)))\n",
        "model.add(TimeDistributed(Dense(n_tags, activation=\"softmax\")))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_split=0.1, class_weight=class_weights_dict, callbacks=[early_stopping])\n",
        "\n",
        "# Save the model\n",
        "model.save('pos_model_with_early_stopping.h5')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaPl5JGUUglt"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open('pos_model_architecture_early_stopping.json', 'w') as f:\n",
        "    f.write(model.to_json())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcvupyqD2K8o"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the model\n",
        "model = load_model('pos_model_with_early_stopping.h5')\n",
        "\n",
        "def predict_with_confidence(sentence):\n",
        "    words = sentence.split()\n",
        "    word_indices = [word2idx.get(word, word2idx[\"UNK\"]) for word in words]\n",
        "    word_indices_padded = pad_sequences([word_indices], maxlen=maxlen, padding='post')\n",
        "    predictions = model.predict(word_indices_padded)\n",
        "\n",
        "    predicted_tags = []\n",
        "    confidence_scores = []\n",
        "\n",
        "    for pred in predictions[0]:\n",
        "        tag_idx = np.argmax(pred)\n",
        "        predicted_tags.append(idx2tag[tag_idx])\n",
        "        confidence_scores.append(pred[tag_idx])\n",
        "\n",
        "    return predicted_tags[:len(words)], confidence_scores[:len(words)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFjLe7rAl7jO",
        "outputId": "525e079b-1c1a-4bad-a235-186fffaae585"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 919ms/step\n",
            "Predicted Tags: ['N', 'PREP', 'N', 'N', 'NUM']\n",
            "Confidence Scores: [0.999986, 0.93083423, 0.7049353, 0.94691956, 0.9999998]\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "sentence = \"Amosi we munaanie Bibilia 23\"\n",
        "predicted_tags, confidence_scores = predict_with_confidence(sentence)\n",
        "print(\"Predicted Tags:\", predicted_tags)\n",
        "print(\"Confidence Scores:\", confidence_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuHFgb4Ol-Up"
      },
      "outputs": [],
      "source": [
        "with open('pos_model_architecture.json', 'w') as f:\n",
        "    f.write(model.to_json())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVs3QhTDBgzUXTFA6yHi/U",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}